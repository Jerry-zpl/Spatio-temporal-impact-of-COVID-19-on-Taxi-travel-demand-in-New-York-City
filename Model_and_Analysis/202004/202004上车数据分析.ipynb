{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004final.xlsx\")\n",
    "train1data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004train1final.xlsx\")\n",
    "train2data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004train2final.xlsx\")\n",
    "train3data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004train3final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = alldata.sort_values(\"LocationID\")\n",
    "data1 = data1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data1[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data1[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data1[['pop_density','commercial_density','road_density','X','Y']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723778108615096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data1[[\"X\"]])\n",
    "Y = np.array(data1[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data1[[\"time\"]])\n",
    "\n",
    "y = np.array(data1[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data1[[\"pop_density\"]])\n",
    "com = np.array(data1[[\"commercial_density\"]])\n",
    "roa = np.array(data1[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results1 = GTWR(coords, t, y, x,80.0 ,0.01 ,kernel='bisquare').fit()\n",
    "\n",
    "results1.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = results1.coords\n",
    "coords = pd.DataFrame(coords)\n",
    "\n",
    "time = results1.t\n",
    "time = pd.DataFrame(time)\n",
    "\n",
    "betas = results1.betas\n",
    "betas = pd.DataFrame(betas)\n",
    "\n",
    "tvalues = results1.tvalues\n",
    "tvalues = pd.DataFrame(tvalues)\n",
    "\n",
    "final_result = pd.concat([time,betas,tvalues,coords], axis = 1)\n",
    "final_result.columns=['time','beta0','POP_beta','COM_beta','ROA_beta','t_beta0','t_POP_beta','t_COM_beta','t_ROA_beta','X','Y']\n",
    "\n",
    "time_data = final_result.sort_values(\"time\")\n",
    "\n",
    "data2 = pd.merge(data1, time_data, left_on=['time','X','Y'], right_on=['time','X','Y'] , how='left')\n",
    "data2 = data2.sort_values(\"time\")\n",
    "data2 = data2.reset_index(drop=True)\n",
    "data2.drop(['Freq','pop_density','commercial_density','road_density'],axis=1,inplace = True)\n",
    "\n",
    "data3 = pd.DataFrame()\n",
    "for j in range(len(data2)):\n",
    "    if abs(data2.iloc[j,8]) > 0 and abs(data2.iloc[j,9]) > 0 and abs(data2.iloc[j,10]) > 0 and abs(data2.iloc[j,11]) > 0 :\n",
    "        a = data2.iloc[j,:]\n",
    "        data3 = pd.concat([data3, a], axis=1, ignore_index = True)\n",
    "\n",
    "data3 = data3.T\n",
    "beta = data3.groupby('time').mean()\n",
    "beta.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta.csv',index=True,sep=',')\n",
    "\n",
    "data = data3.round(6)\n",
    "\n",
    "beta1 = data.groupby('LocationID')['POP_beta'].mean()\n",
    "beta1.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta1.csv',index=True,header = 0,sep=',')\n",
    "\n",
    "beta2 = data.groupby('LocationID')['COM_beta'].mean()\n",
    "beta2.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta2.csv',index=True,header = 0,sep=',')\n",
    "\n",
    "beta3 = data.groupby('LocationID')['ROA_beta'].mean()\n",
    "beta3.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta3.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25032.000000</td>\n",
       "      <td>25032.000000</td>\n",
       "      <td>25032.000000</td>\n",
       "      <td>25032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.350621</td>\n",
       "      <td>1.203110</td>\n",
       "      <td>1.442195</td>\n",
       "      <td>0.408526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.724737</td>\n",
       "      <td>5.331296</td>\n",
       "      <td>4.576755</td>\n",
       "      <td>4.577861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-20.322564</td>\n",
       "      <td>-21.571909</td>\n",
       "      <td>-18.660685</td>\n",
       "      <td>-28.492131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.017783</td>\n",
       "      <td>-0.780799</td>\n",
       "      <td>-0.442191</td>\n",
       "      <td>-1.204774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.347958</td>\n",
       "      <td>0.125220</td>\n",
       "      <td>0.282938</td>\n",
       "      <td>-0.048407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.051475</td>\n",
       "      <td>1.787851</td>\n",
       "      <td>2.421814</td>\n",
       "      <td>1.445771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.943104</td>\n",
       "      <td>43.633399</td>\n",
       "      <td>31.751292</td>\n",
       "      <td>19.909543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3\n",
       "count  25032.000000  25032.000000  25032.000000  25032.000000\n",
       "mean      10.350621      1.203110      1.442195      0.408526\n",
       "std       12.724737      5.331296      4.576755      4.577861\n",
       "min      -20.322564    -21.571909    -18.660685    -28.492131\n",
       "25%        2.017783     -0.780799     -0.442191     -1.204774\n",
       "50%        3.347958      0.125220      0.282938     -0.048407\n",
       "75%       17.051475      1.787851      2.421814      1.445771\n",
       "max       69.943104     43.633399     31.751292     19.909543"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = results1.betas\n",
    "coefficients = pd.DataFrame(betas)\n",
    "coefficients.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvalues = results1.tvalues\n",
    "t = pd.DataFrame(tvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004final.xlsx\")\n",
    "data1 = data.iloc[:,0:2]\n",
    "data2 = pd.concat([data1, coefficients,t], axis = 1)\n",
    "data2.columns=['time','LocationID','beta0','POP_beta','COM_beta','ROA_beta','t_beta0','t_POP_beta','t_COM_beta','t_ROA_beta']\n",
    "data3 = pd.DataFrame()\n",
    "for j in range(len(data2)):\n",
    "    if abs(data2.iloc[j,6]) > 2 and abs(data2.iloc[j,7]) > 2 and abs(data2.iloc[j,8]) > 2 and abs(data2.iloc[j,9]) > 2 :\n",
    "        a = data2.iloc[j,:]\n",
    "        data3 = pd.concat([data3, a], axis=1, ignore_index = True)\n",
    "\n",
    "data3 = data3.T\n",
    "beta = data3.groupby('time').mean()\n",
    "beta.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta.csv',index=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data3.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = data.groupby('LocationID')['POP_beta'].mean()\n",
    "beta1.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta1.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2 = data.groupby('LocationID')['COM_beta'].mean()\n",
    "beta2.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta2.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3 = data.groupby('LocationID')['ROA_beta'].mean()\n",
    "beta3.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta3.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004final.xlsx\")\n",
    "hour = final.iloc[:,0:2]\n",
    "data = pd.concat([hour, coefficients], axis = 1)\n",
    "beta = data.groupby('time').mean()\n",
    "beta.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta.csv',index=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004final.xlsx\")\n",
    "hour = final.iloc[:,0:2]\n",
    "data = pd.concat([hour, coefficients], axis = 1)\n",
    "data.columns=['time','LocationID','beta0','POP_beta','COM_beta','ROA_beta']\n",
    "data = data.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = data.groupby('LocationID')['POP_beta'].mean()\n",
    "beta1.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\pick202004beta1.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  9591.0 , tau:  0.2 , score:  212473.33169064467\n",
      "bw:  5946.0 , tau:  0.2 , score:  212322.75577537267\n",
      "bw:  3693.0 , tau:  0.2 , score:  211953.8693995708\n",
      "bw:  2301.0 , tau:  0.2 , score:  211053.75727800356\n",
      "bw:  1440.0 , tau:  0.2 , score:  209329.2678645656\n",
      "bw:  909.0 , tau:  0.2 , score:  206787.91679011605\n",
      "bw:  580.0 , tau:  0.2 , score:  203512.59761928406\n",
      "bw:  377.0 , tau:  0.2 , score:  200415.47006140952\n",
      "bw:  251.0 , tau:  0.2 , score:  197800.0719899826\n",
      "bw:  174.0 , tau:  0.2 , score:  196854.38320744372\n",
      "bw:  126.0 , tau:  0.2 , score:  196540.44778541557\n",
      "bw:  96.0 , tau:  0.2 , score:  195660.91522446088\n",
      "bw:  78.0 , tau:  0.2 , score:  195587.15567063956\n",
      "bw:  78.0 , tau:  0.2 , score:  195587.15567063956\n",
      "bw:  78.0 , tau:  3.8 , score:  195587.15567063956\n",
      "bw:  78.0 , tau:  0.2 , score:  195587.15567063956\n",
      "bw:  80.0 , tau:  0.2 , score:  195548.82075275638\n",
      "bw:  80.0 , tau:  0.2 , score:  195548.82075275638\n",
      "bw:  80.0 , tau:  0.2 , score:  195548.82075275638\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data1[[\"X\"]])\n",
    "Y = np.array(data1[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data1[[\"time\"]])\n",
    "\n",
    "y = np.array(data1[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data1[[\"pop_density\"]])\n",
    "com = np.array(data1[[\"commercial_density\"]])\n",
    "roa = np.array(data1[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = train1data.sort_values(\"LocationID\")\n",
    "data2 = data2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data2[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data2[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data2[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  5728.0 , tau:  0.2 , score:  125537.39787504295\n",
      "bw:  3559.0 , tau:  0.2 , score:  125302.39443255882\n",
      "bw:  2218.0 , tau:  0.2 , score:  124714.11404995823\n",
      "bw:  1389.0 , tau:  0.2 , score:  123616.14087210444\n",
      "bw:  877.0 , tau:  0.2 , score:  121987.45648196587\n",
      "bw:  560.0 , tau:  0.2 , score:  119915.14990219801\n",
      "bw:  365.0 , tau:  0.2 , score:  118039.2131896007\n",
      "bw:  244.0 , tau:  0.2 , score:  116426.56032078073\n",
      "bw:  169.0 , tau:  0.2 , score:  115857.21064593595\n",
      "bw:  123.0 , tau:  0.2 , score:  115638.0159883876\n",
      "bw:  94.0 , tau:  0.2 , score:  115073.04364268018\n",
      "bw:  77.0 , tau:  0.2 , score:  115006.13055760202\n",
      "bw:  77.0 , tau:  0.2 , score:  115006.13055760202\n",
      "bw:  77.0 , tau:  3.8 , score:  115006.13055760202\n",
      "bw:  77.0 , tau:  0.2 , score:  115006.13055760202\n",
      "bw:  79.0 , tau:  0.2 , score:  114992.05999134232\n",
      "bw:  81.0 , tau:  0.2 , score:  114970.78871338845\n",
      "bw:  81.0 , tau:  0.2 , score:  114970.78871338845\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data2[[\"X\"]])\n",
    "Y = np.array(data2[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data2[[\"time\"]])\n",
    "\n",
    "y = np.array(data2[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data2[[\"pop_density\"]])\n",
    "com = np.array(data2[[\"commercial_density\"]])\n",
    "roa = np.array(data2[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.781028247968878"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data2[[\"X\"]])\n",
    "Y = np.array(data2[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data2[[\"time\"]])\n",
    "\n",
    "y = np.array(data2[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data2[[\"pop_density\"]])\n",
    "com = np.array(data2[[\"commercial_density\"]])\n",
    "roa = np.array(data2[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results2 = GTWR(coords, t, y, x, 81.0 , 0.01 , kernel='bisquare').fit()\n",
    "\n",
    "results2.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = train2data.sort_values(\"LocationID\")\n",
    "data3 = data3.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data3[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data3[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data3[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  6635.0 , tau:  0.2 , score:  145402.96128392537\n",
      "bw:  4119.0 , tau:  0.2 , score:  145200.79632831912\n",
      "bw:  2564.0 , tau:  0.2 , score:  144693.11008322184\n",
      "bw:  1603.0 , tau:  0.2 , score:  143665.1314020664\n",
      "bw:  1009.0 , tau:  0.2 , score:  141939.9611985844\n",
      "bw:  642.0 , tau:  0.2 , score:  139763.0805339909\n",
      "bw:  415.0 , tau:  0.2 , score:  137263.51542975055\n",
      "bw:  275.0 , tau:  0.2 , score:  135368.8931825211\n",
      "bw:  188.0 , tau:  0.2 , score:  134345.10558213477\n",
      "bw:  135.0 , tau:  0.2 , score:  134136.19115951384\n",
      "bw:  101.0 , tau:  0.2 , score:  133498.67462923465\n",
      "bw:  81.0 , tau:  0.2 , score:  133249.2893882733\n",
      "bw:  81.0 , tau:  0.2 , score:  133249.2893882733\n",
      "bw:  81.0 , tau:  3.8 , score:  133249.2893882733\n",
      "bw:  81.0 , tau:  0.2 , score:  133249.2893882733\n",
      "bw:  81.0 , tau:  0.2 , score:  133249.2893882733\n",
      "bw:  81.0 , tau:  0.2 , score:  133249.2893882733\n",
      "bw:  81.0 , tau:  0.2 , score:  133249.2893882733\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data3[[\"X\"]])\n",
    "Y = np.array(data3[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data3[[\"time\"]])\n",
    "\n",
    "y = np.array(data3[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data3[[\"pop_density\"]])\n",
    "com = np.array(data3[[\"commercial_density\"]])\n",
    "roa = np.array(data3[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777367711547866"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data3[[\"X\"]])\n",
    "Y = np.array(data3[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data3[[\"time\"]])\n",
    "\n",
    "y = np.array(data3[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data3[[\"pop_density\"]])\n",
    "com = np.array(data3[[\"commercial_density\"]])\n",
    "roa = np.array(data3[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results3 = GTWR(coords, t, y, x,81.0,0.01, kernel='bisquare').fit()\n",
    "\n",
    "results3.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick202004train3final.xlsx\")\n",
    "train3data = train3data.rename(columns={'Unnamed: 0':'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = train3data.sort_values(\"LocationID\")\n",
    "data4 = data4.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data4[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data4[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data4[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  7628.0 , tau:  0.2 , score:  168065.7404294817\n",
      "bw:  4733.0 , tau:  0.2 , score:  167888.98680405287\n",
      "bw:  2943.0 , tau:  0.2 , score:  167439.6381275933\n",
      "bw:  1838.0 , tau:  0.2 , score:  166419.12874583135\n",
      "bw:  1154.0 , tau:  0.2 , score:  164679.58018913787\n",
      "bw:  732.0 , tau:  0.2 , score:  162211.0788252475\n",
      "bw:  470.0 , tau:  0.2 , score:  159381.10555140363\n",
      "bw:  309.0 , tau:  0.2 , score:  157196.1179123442\n",
      "bw:  209.0 , tau:  0.2 , score:  155536.98707965307\n",
      "bw:  148.0 , tau:  0.2 , score:  155240.3735503658\n",
      "bw:  109.0 , tau:  0.2 , score:  154708.02008551732\n",
      "bw:  86.0 , tau:  0.2 , score:  154275.99996506804\n",
      "bw:  86.0 , tau:  0.2 , score:  154275.99996506804\n",
      "bw:  86.0 , tau:  0.2 , score:  154275.99996506804\n",
      "bw:  80.0 , tau:  0.2 , score:  154188.08728755746\n",
      "bw:  80.0 , tau:  0.2 , score:  154188.08728755746\n",
      "bw:  80.0 , tau:  0.2 , score:  154188.08728755746\n",
      "bw:  80.0 , tau:  0.2 , score:  154188.08728755746\n",
      "bw:  81.0 , tau:  0.2 , score:  154177.08896125937\n",
      "bw:  81.0 , tau:  0.2 , score:  154177.08896125937\n",
      "bw:  81.0 , tau:  0.2 , score:  154177.08896125937\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data4[[\"X\"]])\n",
    "Y = np.array(data4[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data4[[\"time\"]])\n",
    "\n",
    "y = np.array(data4[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data4[[\"pop_density\"]])\n",
    "com = np.array(data4[[\"commercial_density\"]])\n",
    "roa = np.array(data4[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.777507220640079"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data4[[\"X\"]])\n",
    "Y = np.array(data4[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data4[[\"time\"]])\n",
    "\n",
    "y = np.array(data4[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data4[[\"pop_density\"]])\n",
    "com = np.array(data4[[\"commercial_density\"]])\n",
    "roa = np.array(data4[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results4 = GTWR(coords, t, y, x,81.0,0.01, kernel='bisquare').fit()\n",
    "\n",
    "results4.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
