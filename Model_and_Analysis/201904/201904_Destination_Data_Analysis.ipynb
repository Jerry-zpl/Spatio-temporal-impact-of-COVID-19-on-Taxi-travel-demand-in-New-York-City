{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\drop201904final.xlsx\")\n",
    "train1data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\drop201904train1final.xlsx\")\n",
    "train2data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\drop201904train2final.xlsx\")\n",
    "train3data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\drop201904train3final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = alldata.sort_values(\"LocationID\")\n",
    "data1 = data1.reset_index(drop=True)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data1[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data1[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data1[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8544903629911434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data1[[\"X\"]])\n",
    "Y = np.array(data1[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data1[[\"time\"]])\n",
    "\n",
    "y = np.array(data1[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data1[[\"pop_density\"]])\n",
    "com = np.array(data1[[\"commercial_density\"]])\n",
    "roa = np.array(data1[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results1 = GTWR(coords, t, y, x,95.0,0.01, kernel='bisquare').fit()\n",
    "\n",
    "results1.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = results1.coords\n",
    "coords = pd.DataFrame(coords)\n",
    "\n",
    "time = results1.t\n",
    "time = pd.DataFrame(time)\n",
    "\n",
    "betas = results1.betas\n",
    "betas = pd.DataFrame(betas)\n",
    "\n",
    "tvalues = results1.tvalues\n",
    "tvalues = pd.DataFrame(tvalues)\n",
    "\n",
    "final_result = pd.concat([time,betas,tvalues,coords], axis = 1)\n",
    "final_result.columns=['time','beta0','POP_beta','COM_beta','ROA_beta','t_beta0','t_POP_beta','t_COM_beta','t_ROA_beta','X','Y']\n",
    "\n",
    "time_data = final_result.sort_values(\"time\")\n",
    "\n",
    "data2 = pd.merge(data1, time_data, left_on=['time','X','Y'], right_on=['time','X','Y'] , how='left')\n",
    "data2 = data2.sort_values(\"time\")\n",
    "data2 = data2.reset_index(drop=True)\n",
    "data2.drop(['Freq','pop_density','commercial_density','road_density'],axis=1,inplace = True)\n",
    "\n",
    "data3 = pd.DataFrame()\n",
    "for j in range(len(data2)):\n",
    "    if abs(data2.iloc[j,8]) > 0 and abs(data2.iloc[j,9]) > 0 and abs(data2.iloc[j,10]) > 0 and abs(data2.iloc[j,11]) > 0 :\n",
    "        a = data2.iloc[j,:]\n",
    "        data3 = pd.concat([data3, a], axis=1, ignore_index = True)\n",
    "\n",
    "data3 = data3.T\n",
    "beta = data3.groupby('time').mean()\n",
    "beta.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta.csv',index=True,sep=',')\n",
    "\n",
    "data = data3.round(6)\n",
    "\n",
    "beta1 = data.groupby('LocationID')['POP_beta'].mean()\n",
    "beta1.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta1.csv',index=True,header = 0,sep=',')\n",
    "\n",
    "beta2 = data.groupby('LocationID')['COM_beta'].mean()\n",
    "beta2.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\drop201904beta2.csv',index=True,header = 0,sep=',')\n",
    "\n",
    "beta3 = data.groupby('LocationID')['ROA_beta'].mean()\n",
    "beta3.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta3.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43049.000000</td>\n",
       "      <td>43049.000000</td>\n",
       "      <td>43049.000000</td>\n",
       "      <td>43049.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.475290</td>\n",
       "      <td>36.898223</td>\n",
       "      <td>-4.981372</td>\n",
       "      <td>28.511118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>245.368811</td>\n",
       "      <td>81.807197</td>\n",
       "      <td>57.406587</td>\n",
       "      <td>98.615936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-93.986451</td>\n",
       "      <td>-210.408486</td>\n",
       "      <td>-404.395837</td>\n",
       "      <td>-315.933522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.739776</td>\n",
       "      <td>-1.754296</td>\n",
       "      <td>-5.346363</td>\n",
       "      <td>-6.899202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.236211</td>\n",
       "      <td>2.670496</td>\n",
       "      <td>1.351031</td>\n",
       "      <td>1.276369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>136.544686</td>\n",
       "      <td>28.510232</td>\n",
       "      <td>13.691623</td>\n",
       "      <td>32.181494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1100.789497</td>\n",
       "      <td>467.291673</td>\n",
       "      <td>257.750618</td>\n",
       "      <td>563.003050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3\n",
       "count  43049.000000  43049.000000  43049.000000  43049.000000\n",
       "mean     154.475290     36.898223     -4.981372     28.511118\n",
       "std      245.368811     81.807197     57.406587     98.615936\n",
       "min      -93.986451   -210.408486   -404.395837   -315.933522\n",
       "25%       10.739776     -1.754296     -5.346363     -6.899202\n",
       "50%       32.236211      2.670496      1.351031      1.276369\n",
       "75%      136.544686     28.510232     13.691623     32.181494\n",
       "max     1100.789497    467.291673    257.750618    563.003050"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas = results1.betas\n",
    "coefficients = pd.DataFrame(betas)\n",
    "coefficients.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvalues = results1.tvalues\n",
    "t = pd.DataFrame(tvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\drop201904final.xlsx\")\n",
    "data1 = data.iloc[:,0:2]\n",
    "data2 = pd.concat([data1, coefficients,t], axis = 1)\n",
    "data2.columns=['time','LocationID','beta0','POP_beta','COM_beta','ROA_beta','t_beta0','t_POP_beta','t_COM_beta','t_ROA_beta']\n",
    "data3 = pd.DataFrame()\n",
    "for j in range(len(data2)):\n",
    "    if abs(data2.iloc[j,6]) > 2 and abs(data2.iloc[j,7]) > 2 and abs(data2.iloc[j,8]) > 2 and abs(data2.iloc[j,9]) > 2 :\n",
    "        a = data2.iloc[j,:]\n",
    "        data3 = pd.concat([data3, a], axis=1, ignore_index = True)\n",
    "\n",
    "data3 = data3.T\n",
    "beta = data3.groupby('time').mean()\n",
    "beta.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta.csv',index=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data3.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = data.groupby('LocationID')['POP_beta'].mean()\n",
    "beta1.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta1.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta2 = data.groupby('LocationID')['COM_beta'].mean()\n",
    "beta2.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta2.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta3 = data.groupby('LocationID')['ROA_beta'].mean()\n",
    "beta3.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta3.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\drop201904final.xlsx\")\n",
    "hour = final.iloc[:,0:2]\n",
    "data = pd.concat([hour, coefficients], axis = 1)\n",
    "beta = data.groupby('time').mean()\n",
    "beta.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta.csv',index=True,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_excel(\"E:\\\\Capstone Project\\\\Data\\\\Taxi_area\\\\pick201904final.xlsx\")\n",
    "hour = final.iloc[:,0:2]\n",
    "data = pd.concat([hour, coefficients], axis = 1)\n",
    "data.columns=['time','LocationID','beta0','POP_beta','COM_beta','ROA_beta']\n",
    "data = data.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = data.groupby('LocationID')['POP_beta'].mean()\n",
    "beta1.to_csv(r'E:\\\\Capstone Project\\\\Data\\\\paper\\\\drop201904beta1.csv',index=True,header = 0,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  16473.0 , tau:  0.2 , score:  618121.6257382701\n",
      "bw:  10199.0 , tau:  0.2 , score:  618040.4101147114\n",
      "bw:  6322.0 , tau:  0.2 , score:  618013.6429108008\n",
      "bw:  6322.0 , tau:  0.2 , score:  618013.6429108008\n",
      "bw:  7803.0 , tau:  0.2 , score:  618012.8451231152\n",
      "bw:  7803.0 , tau:  0.2 , score:  618012.8451231152\n",
      "bw:  7237.0 , tau:  0.2 , score:  618011.4716995397\n",
      "bw:  7237.0 , tau:  0.2 , score:  618011.4716995397\n",
      "bw:  7237.0 , tau:  0.2 , score:  618011.4716995397\n",
      "bw:  7104.0 , tau:  0.2 , score:  618010.9732369512\n",
      "bw:  7104.0 , tau:  0.2 , score:  618010.9732369512\n",
      "bw:  7154.0 , tau:  0.2 , score:  618010.9717674355\n",
      "bw:  7154.0 , tau:  0.2 , score:  618010.9717674355\n",
      "bw:  7154.0 , tau:  0.2 , score:  618010.9717674355\n",
      "bw:  7154.0 , tau:  0.2 , score:  618010.9717674355\n",
      "bw:  7147.0 , tau:  0.2 , score:  618010.9713764497\n",
      "bw:  7147.0 , tau:  0.2 , score:  618010.9713764497\n",
      "bw:  7149.0 , tau:  0.2 , score:  618010.971285641\n",
      "bw:  7151.0 , tau:  0.2 , score:  618010.97117543\n",
      "bw:  7151.0 , tau:  0.2 , score:  618010.97117543\n",
      "bw:  7151.0 , tau:  0.2 , score:  618010.97117543\n",
      "bw:  7151.0 , tau:  0.2 , score:  618010.97117543\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data1[[\"X\"]])\n",
    "Y = np.array(data1[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data1[[\"time\"]])\n",
    "\n",
    "y = np.array(data1[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data1[[\"pop_density\"]])\n",
    "com = np.array(data1[[\"commercial_density\"]])\n",
    "roa = np.array(data1[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = train1data.sort_values(\"LocationID\")\n",
    "data2 = data2.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data2[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data2[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data2[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  9931.0 , tau:  0.2 , score:  374232.1362124678\n",
      "bw:  6156.0 , tau:  0.2 , score:  374221.2825786954\n",
      "bw:  6156.0 , tau:  0.2 , score:  374221.2825786954\n",
      "bw:  7598.0 , tau:  0.2 , score:  374219.20727567375\n",
      "bw:  7598.0 , tau:  0.2 , score:  374219.20727567375\n",
      "bw:  7047.0 , tau:  0.2 , score:  374218.62073201645\n",
      "bw:  7047.0 , tau:  0.2 , score:  374218.62073201645\n",
      "bw:  7047.0 , tau:  0.2 , score:  374218.62073201645\n",
      "bw:  7047.0 , tau:  0.2 , score:  374218.62073201645\n",
      "bw:  7128.0 , tau:  0.2 , score:  374218.6174865873\n",
      "bw:  7128.0 , tau:  0.2 , score:  374218.6174865873\n",
      "bw:  7097.0 , tau:  0.2 , score:  374218.61744851334\n",
      "bw:  7097.0 , tau:  0.2 , score:  374218.61744851334\n",
      "bw:  7109.0 , tau:  0.2 , score:  374218.61731266015\n",
      "bw:  7116.0 , tau:  0.2 , score:  374218.61717151885\n",
      "bw:  7116.0 , tau:  0.2 , score:  374218.61717151885\n",
      "bw:  7116.0 , tau:  0.2 , score:  374218.61717151885\n",
      "bw:  7116.0 , tau:  0.2 , score:  374218.61717151885\n",
      "bw:  7116.0 , tau:  0.2 , score:  374218.61717151885\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data2[[\"X\"]])\n",
    "Y = np.array(data2[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data2[[\"time\"]])\n",
    "\n",
    "y = np.array(data2[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data2[[\"pop_density\"]])\n",
    "com = np.array(data2[[\"commercial_density\"]])\n",
    "roa = np.array(data2[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547299277990237"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data2[[\"X\"]])\n",
    "Y = np.array(data2[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data2[[\"time\"]])\n",
    "\n",
    "y = np.array(data2[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data2[[\"pop_density\"]])\n",
    "com = np.array(data2[[\"commercial_density\"]])\n",
    "roa = np.array(data2[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results2 = GTWR(coords, t, y, x,95.0,0.01, kernel='bisquare').fit()\n",
    "\n",
    "results2.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = train2data.sort_values(\"LocationID\")\n",
    "data3 = data3.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data3[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data3[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data3[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw:  11557.0 , tau:  0.2 , score:  434008.1784943743\n",
      "bw:  7161.0 , tau:  0.2 , score:  433960.68900648796\n",
      "bw:  4444.0 , tau:  0.2 , score:  433956.2330407859\n",
      "bw:  4444.0 , tau:  0.2 , score:  433956.2330407859\n",
      "bw:  5482.0 , tau:  0.2 , score:  433952.9543324626\n",
      "bw:  5482.0 , tau:  0.2 , score:  433952.9543324626\n",
      "bw:  5085.0 , tau:  0.2 , score:  433951.41666357015\n",
      "bw:  4840.0 , tau:  0.2 , score:  433949.4721122331\n",
      "bw:  4689.0 , tau:  0.2 , score:  433949.4457412935\n",
      "bw:  4689.0 , tau:  0.2 , score:  433949.4457412935\n",
      "bw:  4689.0 , tau:  0.2 , score:  433949.4457412935\n",
      "bw:  4689.0 , tau:  0.2 , score:  433949.4457412935\n",
      "bw:  4710.0 , tau:  0.2 , score:  433949.4417165454\n",
      "bw:  4724.0 , tau:  0.2 , score:  433949.43815734424\n",
      "bw:  4732.0 , tau:  0.2 , score:  433949.4358087967\n",
      "bw:  4738.0 , tau:  0.2 , score:  433949.43559738935\n",
      "bw:  4738.0 , tau:  0.2 , score:  433949.43559738935\n",
      "bw:  4738.0 , tau:  0.2 , score:  433949.43559738935\n",
      "bw:  4738.0 , tau:  0.2 , score:  433949.43559738935\n",
      "bw:  4737.0 , tau:  0.2 , score:  433949.4350571957\n",
      "bw:  4737.0 , tau:  0.2 , score:  433949.4350571957\n",
      "bw:  4737.0 , tau:  0.2 , score:  433949.4350571957\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data3[[\"X\"]])\n",
    "Y = np.array(data3[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data3[[\"time\"]])\n",
    "\n",
    "y = np.array(data3[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data3[[\"pop_density\"]])\n",
    "com = np.array(data3[[\"commercial_density\"]])\n",
    "roa = np.array(data3[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542127205514243"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data3[[\"X\"]])\n",
    "Y = np.array(data3[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data3[[\"time\"]])\n",
    "\n",
    "y = np.array(data3[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data3[[\"pop_density\"]])\n",
    "com = np.array(data3[[\"commercial_density\"]])\n",
    "roa = np.array(data3[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results3 = GTWR(coords, t, y, x,95.0,0.01, kernel='bisquare').fit()\n",
    "\n",
    "results3.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = train3data.sort_values(\"LocationID\")\n",
    "data4 = data4.reset_index(drop=True)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data4[['pop_density','commercial_density','road_density','X','Y']])\n",
    "data4[['pop_density','commercial_density','road_density','X','Y']] = scaler.transform(data4[['pop_density','commercial_density','road_density','X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data4[[\"X\"]])\n",
    "Y = np.array(data4[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data4[[\"time\"]])\n",
    "\n",
    "y = np.array(data4[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data4[[\"pop_density\"]])\n",
    "com = np.array(data4[[\"commercial_density\"]])\n",
    "roa = np.array(data4[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.sel import search_GTWRparameter\n",
    "\n",
    "sel = search_GTWRparameter(coords, t, y, x, kernel = 'bisquare')\n",
    "\n",
    "bw, tau = sel.search(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8550205204450262"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(data4[[\"X\"]])\n",
    "Y = np.array(data4[[\"Y\"]])\n",
    "coords = np.hstack([X,Y])\n",
    "\n",
    "t = np.array(data4[[\"time\"]])\n",
    "\n",
    "y = np.array(data4[[\"Freq\"]])\n",
    "\n",
    "pop = np.array(data4[[\"pop_density\"]])\n",
    "com = np.array(data4[[\"commercial_density\"]])\n",
    "roa = np.array(data4[[\"road_density\"]])\n",
    "x = np.hstack([pop,com,roa])\n",
    "\n",
    "from gtwr.model import GTWR\n",
    "\n",
    "results4 = GTWR(coords, t, y, x,95.0,0.01, kernel='bisquare').fit()\n",
    "\n",
    "results4.R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
